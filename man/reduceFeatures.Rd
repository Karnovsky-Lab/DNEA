% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/collapseNodes-fun.R
\name{reduceFeatures}
\alias{reduceFeatures}
\title{Collapse correlated features into a single goup}
\usage{
reduceFeatures(
  object,
  method = c("correlation", "knowledge", "hybrid"),
  correlation_threshold = NULL,
  feature_groups = NULL
)
}
\arguments{
\item{object}{A \code{DNEAresults} object}

\item{method}{A character string that dictates the collapsing method to use. The available methods are: "correlation",
"knowledge", or "hybrid"}

\item{correlation_threshold}{A threshold wherein features correlated above correlation_threshold
will be collapsed into one. This parameter is only necessary for the correlation and hybrid
methods}

\item{feature_groups}{A data.frame containing group information for the collapsing algorithm
indicated by the "knowledge" and "hybrid" methods}
}
\value{
A \code{collapsed_DNEAresults} object.
}
\description{
This function takes as input a DNEAresults object and collapses highly correlated features within the non-normalized,
non-transformed data using one of three methods:  \cr

\enumerate{
\item \strong{correlation-based}
\item \strong{knowledge-based}
\item \strong{hybrid}}

More info about the different approaches can be found in the \strong{\emph{Details}} section.
Highly correlated groups of features are collapsed by taking the mean expression of all features.

\strong{\emph{NOTE:}} This method was developed using non-normalized, non-transformed data and this fact is critical for feature
collapsing since the mean expression value is used for each group. Normalized data may alter the results of collapsing.
}
\details{
Due to the computational complexity of the DNEAdev algorithm, the processing time for a given dataset increases dramatically as the
number of features increases. The ability to process each replicate performed in  \code{\link{stabilitySelection}} in
parallel helps circumvent this issue, however, a user may still be constrained by the resources available to them (ie. a
limited number of cpu cores or memory). Collapsing related features into groups is another method by which the user can
reduce the complexity of the analysis, and as a result decrease the necessary resources.  \cr

In a related scenario, you may also have many highly-correlated features of the same class of compounds
(ie. fatty acids, carnitines, etc.), and network analysis at the resolution of these individual features is not
important. Collapsing features would decrease the computing time without losing critical information to the analysis
(Please see the \strong{\emph{Details}} section of \code{\link{createDNEAobject}} for more information about the motivation
behind collapsing highly correlated features). \cr

Ultimately, this function allows the user to reduce the complexity of the dataset and reduce the computational power necessary
for the analysis and/or improve the quality of the results. The most appropriate method to use when collapsing data
is dependent on the dataset and prior information known about the features. The following text explains more about each
method and the best use cases:  \cr

\enumerate{
\item \strong{correlation-based - } The user specifies a correlation threshold wherein features with a higher pearson correlation value
than the threshold are collapsed into one group. This approach is best when no prior information about the features are known. \cr

\item \strong{knowledge-based - } The user specifies feature groups based on a priori information (ie. all of the carnitines in a dataset
are specified as a single group) and the features within each group are collapsed into one feature. This approach is best in
experiments where the dataset contains many highly similar compounds, like fatty acids, carnitines, ceramides, etc. \cr

\item \strong{hybrid - } The user specifies both a correlation threshold, like in the correlation-based approach, and feature groups
based on \emph{a priori} information similar to the knowledge-based approach. The features within each user-specified group that
have a higher pearson correlation than the provided threshold are collapsed into one group. This approach is best in
experiments where the dataset contains many compounds of a similar class, but the user is unsure how correlated the features of
said class will be. This method prevents poorly correlated or uncorrelated features from being collapsed into a single feature.}
}
\examples{
#import example data
data(dnw)

#simulate group labels
TEDDY_groups <- data.frame(features = rownames(expressionData(dnw, normalized = FALSE)),
                           groups = rownames(expressionData(dnw, normalized = FALSE)),
                           row.names = rownames(expressionData(dnw, normalized = FALSE)))

TEDDY_groups$groups[TEDDY_groups$groups \%in\% c("isoleucine", "leucine", "valine")] <- "BCAAs"
TEDDY_groups$groups[grep("acid", TEDDY_groups$groups)] <- "fatty_acids"


collapsed_TEDDY <- reduceFeatures(object = dnw,
                                  method = "hybrid",
                                  correlation_threshold = 0.7,
                                  feature_groups = TEDDY_groups)

}
\seealso{
\code{\link{createDNEAobject}}, \code{\link{stabilitySelection}}
}
\author{
Christopher Patsalis
}
